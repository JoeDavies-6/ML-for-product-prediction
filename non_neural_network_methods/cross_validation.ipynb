{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"prediction.ipynb","provenance":[],"authorship_tag":"ABX9TyPmBZ1gqi1rKkO7a1uueafr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"K1xs0Dc5dC-2"},"outputs":[],"source":["# Import required packages\n","import time\n","import os\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","import sys\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import PowerTransformer\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.gaussian_process import GaussianProcessRegressor\n","from sklearn.model_selection import cross_val_score\n","import time\n","from sklearn.metrics import mean_absolute_error\n","from scipy.optimize import curve_fit\n","from sklearn.decomposition import PCA\n","import seaborn as sns\n"]},{"cell_type":"code","source":["### The code in this cell uses the functions defined below to run cross-validation using each feature list\n","# Define the infile\n","infile = \"/content/drive/MyDrive/Colab Notebooks/results\"\n","# Define feature sets. ls1 will also be used for yeo-johnson green cumulative, and ls2 will also have PCA applied\n","feature_ls1 = ['green_cumulative']\n","feature_ls2 = ['green', 'red', 'blue', 'uvaI', 'uvaE', 'uvbE', 'uvbI', 'stirRate', \n","               'pressureE', 'humidity', 'temperature', 'best_temperature', 'hydrazine_batches', \n","               'luminance_percent', 'saturation', 'hue', 'red_cumulative', 'blue_cumulative', \n","               'green_cumulative', 'pressureE_cumulative', 'best_temperature_cumulative', \n","               'hue_cumulative', 'saturation_cumulative', 'luminance_percent_cumulative', \n","               'humidity_cumulative', 'best_temperature_std_dev', 'best_temperature_std_dev_cumulative', \n","               'std_dev_over_cum_temp', 'std_dev_cumulative_over_cumulative_temp']\n","feature_ls3 = ['uvaI', 'uvaE', 'uvbE', 'uvbI', 'stirRate', \n","               'pressureE', 'humidity', 'temperature', 'best_temperature', 'hydrazine_batches', \n","               'pressureE_cumulative', 'best_temperature_cumulative', \n","               'humidity_cumulative', 'best_temperature_std_dev', 'best_temperature_std_dev_cumulative', \n","               'std_dev_over_cum_temp', 'std_dev_cumulative_over_cumulative_temp']\n","# Define lists of feature sets and models. Then create dictionary which includes the names\n","feature_ls_ls = [feaure_ls1, feature_ls2, feature_ls3]\n","model_ls = [linear_regression, polynomial_regression, gradient_boosting_regressor, random_forest]\n","feature_ls_folder_name_dic = {''.join(feature_ls1): 'Green cumulative/', ''.join(feature_ls2): 'All features/', ''.join(feature_ls3): 'No colour features/'}\n","# Iterate through the lists + models to do cross-validation on all combinations of interest\n","for feature_ls in feature_ls_ls:\n","\n","  for model in model_ls:\n","    # if polynomial only do green cumulative feature and don't scale\n","    if model == polynomial_regression:\n","      if len(feature_ls) > 1:\n","        continue\n","      cross_validation(model, feature_ls, feature_ls_folder_name_dic[''.join(feature_ls)], model.__name__, infile, scale=False)\n","      cross_validation(model, feature_ls, \"Yeo-Johnson \" + feature_ls_folder_name_dic[''.join(feature_ls)], model.__name__, infile, scale=False, yeo_johnson=True)\n","    # if not polynomial, \n","    else:\n","      cross_validation(model, feature_ls, feature_ls_folder_name_dic[''.join(feature_ls)], model.__name__, infile)\n","      if feature_ls == feature_ls1:\n","        # if green cumulative repeat with YJ transform\n","        cross_validation(model, feature_ls, \"Yeo-Johnson \" + feature_ls_folder_name_dic[''.join(feature_ls)], model.__name__, infile, yeo_johnson=True)\n","      elif feature_ls == feature_ls2:\n","        # if all features repeat with pca\n","        cross_validation(model, feature_ls, \"PCA/\", model.__name__, infile pca=True)"],"metadata":{"id":"5_SOMvPmRzIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def open_dataframe(in_file):\n","  # Load csv as a Pandas DataFrame from in_file location\n","  in_file = os.path.join(in_file)\n","  df = pd.read_csv(in_file, header=0, index_col='crocus_id', parse_dates=[\"datetime\"])\n","  # The experiment Crocus-024 was removed due to inadequate data types\n","  if any(df.loc['Crocus-024']):\n","    df.drop('Crocus-024', inplace=True)\n","  return df"],"metadata":{"id":"Pkvp0hnkdRa8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def cross_validation(model_func, features, feature_folder, model_folder, infile, yeo_johnson=False, pca=False, scale=True):\n","  \"\"\"\n","  model_func: function object, which ML method to use. E.g., Linear regression, or random forest, etc.\n","  features: list, which set of features to use\n","  feature_folder: str, the name used for this set of features to save metadata\n","  model_folder: str, the name used for this model to save metadata\n","  infile: str, save location for file\n","  yeo_johnson: bool, whether to include the Yeo-Johnson power transform\n","  pca: bool, whether to apply pca to the feature list to reduce dimensionality\n","  scale: bool, whether to apply scalar to the feature data. \n","  \n","  This function takes a model and a list of features and will perform cross validation for that model and feature set\"\"\"\n","\n","  file_check = infile + feature_folder + model_folder +\".csv\"\n","  # if the file exists then skip\n","  if os.path.exists(file_check):\n","    return \n","  # The dataframe is opened\n","  df = open_dataframe()\n","  # a list of reaction runs is made and sorted.\n","  run_list = sorted(list(set(df.index)))\n","  run_list_iter = run_list\n","  results_ls = []\n","  # iterate through runs\n","  for run in run_list_iter:\n","    # split into test and training runs\n","    test_run = run\n","    training_runs = [x for x in run_list if x != run]\n","    # split data into test and train data\n","    train_df = df.loc[training_runs]\n","    test_df = df.loc[run]\n","    # split data into x and y for test and training\n","    x_train = train_df[features]\n","    y_train = train_df['Product']\n","    x_test = test_df[features]\n","    y_test = test_df['Product']\n","    # # Scale and then power transform data\n","    if scale is True:\n","      ss = StandardScaler()\n","      x_train = ss.fit_transform(x_train)\n","      x_test = ss.transform(x_test)\n","    # apply pca if true until 95% explained variance is reached\n","    if pca is True:\n","        for i in range(1, len(features)):\n","          print(i)\n","          pca = PCA(n_components=i)\n","          principalComponents = pca.fit_transform(x_train)\n","          print(f'with {i} principal components explained variance is:', pca.explained_variance_ratio_,\n","                \"and the total is:\", sum(pca.explained_variance_ratio_))\n","          if sum(pca.explained_variance_ratio_) > 0.95:\n","              break\n","        x_train = pca.fit_transform(x_train)\n","        x_test = pca.transform(x_test)\n","    # if yeo-johnson is true then power transform the data\n","    if yeo_johnson is True:\n","      pt = PowerTransformer(method='yeo-johnson')\n","      x_train = pt.fit_transform(x_train)\n","      x_test = pt.transform(x_test)\n","    # train model\n","    trained_model = model_func(x_train, y_train)\n","    # test model\n","    y_pred = trained_model.predict(x_test)\n","    # evaluate predictions\n","    mae = mean_absolute_error(y_test, y_pred)\n","    # plots predictions vs actual product to provide visual assessment of accuracy\n","    \n","      # plt.text(1, 25, mae)\n","      # plt.xlim(0, 40)\n","      # plt.ylim(0, 40)\n","      # plt.plot(y_pred, y_test, linewidth=2, label=test_run, c='black')\n","      # plt.ylabel('Actual')\n","      # plt.xlabel('Predictions')\n","      # plt.show()\n","\n","    # per file, only 1 model, 1 feature set but each cross validation (10 runs)\n","    results_df = pd.DataFrame({'test_run': [test_run], 'training_runs': [training_runs], 'features': [features], 'model': [model_folder], 'mae': [mae]})\n","    results_ls.append(results_df)\n","  cv_results_df = pd.concat(results_ls)\n","  average_mae = np.mean(cv_results_df['mae'])\n","  average_row = pd.DataFrame({'test_run': 'average', 'training_runs': 'average', 'features': [features], 'model': [model_folder], 'mae': average_mae})\n","  cv_results_df_save = pd.concat([cv_results_df, average_row])\n","  # if no folder, make a new one\n","  directory_check = infile + feature_folder\n","  if not os.path.exists(directory_check):\n","    os.makedirs(directory_check)\n","  cv_results_df_save.to_csv(infile + feature_folder + model_folder +\".csv\")\n"],"metadata":{"id":"eJBR9y9elNGz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"Models\"\"\"\n","def linear_regression(x_train, y_train):\n","    \"\"\"Runs a linear regressor and sends the object back for evaluation\"\"\"\n","    regressor = LinearRegression(fit_intercept=True)\n","    regressor.fit(x_train, y_train)\n","    return regressor\n","\n","def gradient_boosting_regressor(x_train, y_train):\n","    \"\"\"Runs a gradient boosting regressor and sends the object back for evaluation\"\"\"\n","    regressor = GradientBoostingRegressor(n_estimators=1000, random_state=0)\n","    regressor.fit(x_train, y_train)\n","    return regressor\n","  \n","def random_forest(x_train, y_train):\n","    \"\"\"Runs a random forest regressor and sends the object back for evaluation\"\"\"\n","    regressor = RandomForestRegressor(n_estimators=1000, random_state=0)\n","    regressor.fit(x_train, y_train)\n","    return regressor\n","\n","def polynomial_regression(x_train, y_train):\n","  \"\"\"Runs a polynomial regressor and sends the object back for evaluation\"\"\"\n","  regressor = PolynomialRegressor()\n","  regressor.fit(x_train, y_train)\n","  return regressor"],"metadata":{"id":"BX6roi-lqJR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PolynomialRegressor:\n","  \"\"\"For polynomial regressor model\"\"\"\n","  def __init__(self):\n","    pass\n","\n","  def cubic_polynomial(self, x, a, b, c, d=0):\n","    z = a * x + b * x ** 2 + c * x ** 3 + d\n","    return z\n","\n","  def fit_transform(self, x, y):\n","    # need to reshape arrrays\n","    n = len(x)\n","    assert n == len(y), \"x and y must have same length\"\n","    x, y = x.values.reshape(n,), y.values.reshape(n, )\n","    self.coeffs, cov = curve_fit(f=self.cubic_polynomial, xdata=x, ydata=y, p0=[0, 0, 0], bounds=(-np.inf, np.inf))\n","    y_train_pred = self.cubic_polynomial(x_train, *self.coeffs)\n","    return y_train_pred\n","\n","  def fit(self, x, y):\n","    n = len(x)\n","    assert n == len(y), \"x and y must have same length\"\n","    if isinstance(x, np.ndarray):\n","      x, y = x.reshape(n,), y.values.reshape(n, )\n","    elif isinstance(x, pd.Series):\n","      x, y = x.values.reshape(n,), y.values.reshape(n, )\n","    self.coeffs, cov = curve_fit(f=self.cubic_polynomial, xdata=x, ydata=y, p0=[0, 0, 0], bounds=(-np.inf, np.inf))\n","\n","  def predict(self, x):\n","    n = len(x)\n","    if isinstance(x, np.ndarray):\n","      x = x.reshape(n, )\n","    elif isinstance(x, pd.Series):\n","      x = x.values.reshape(n,)\n","    y_pred = self.cubic_polynomial(x, *self.coeffs)\n","    return y_pred\n"],"metadata":{"id":"FXPxFT8c2uKH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"7J0rf9nyeMBj"},"execution_count":null,"outputs":[]}]}